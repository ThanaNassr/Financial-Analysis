# -*- coding: utf-8 -*-
"""TASKC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q6Q82AgYdz9yh3o9SGp7YxwF22PvwH_Z
"""

import pandas as pd
from google.colab import files
uploaded = files.upload()
df = pd.read_csv("motor_insurance_recovery_cleaned final.csv")

# 3.1 Exploratory Relationship Analysis
import seaborn as sns
import matplotlib.pyplot as plt

#Get all columns that might have an association with claim amounts
# We could do all columns here too ? Need to check this !
selected_columns = [
    "total_claim_amount",
    "general_damages",
    "medical_treatment_costs",
    "injury_duration_days",
    "work_absence_duration_days",
    "rehabilitation_recommended",
    "rehabilitation_completed",
    "hospital_visit_required",
    "hospital_admission_required",
    "car_damage_score",
    "emergency_score",
    "claim_value_score",
    "claimant_age_at_incident",
    "insurance_deductible_amount"
]

# Map car_damage_severity to numeric score for analysis
car_damage_map = {"none": 0, "minor": 1, "moderate": 2, "severe": 3}
df["car_damage_score"] = df["car_damage_severity"].map(car_damage_map)

#For all other categorical columns, we try to give them a numeric scale to be able to do out correlation analysis :

# Emergency services
emergency_map = {
    "none": 0,
    "police": 1,
    "ambulance": 1,
    "ambulance_and_police": 2
}
df["emergency_score"] = df["emergency_services_attended"].map(emergency_map)

# Claim value category
df["claim_value_score"] = df["claim_value_category"].astype(float)

selected_df = df[selected_columns]
# Correlation values with total claim amount
correlations = selected_df.corr()["total_claim_amount"].sort_values(ascending=False)
print(correlations)

# Heatmap
plt.figure(figsize=(12,8))
sns.heatmap(selected_df.corr(), cmap="coolwarm", annot=True)
plt.title("Correlation Heatmap of Selected Features")
plt.show()

"""From this heatmap we can see a higher correlation of claim amounts with injury duration days and general damaages and a moderate correlation with medical treatmnt costs and work absence days.There appears to be multicollinearity between injury duration days and general damages. Since these two variables are strongly correlated, including both in the regression model may lead to unstable coefficient estimates and reduced model reliability"""

print("Original values:", df["car_damage_severity"].unique())
print(df[["car_damage_severity", "car_damage_score"]].head(10))
df[df["car_damage_score"].isna()]["car_damage_severity"].value_counts()
df["car_damage_severity"] = df["car_damage_severity"].str.strip().str.lower()

#Scatter plot for general damages vs claim amounts
plt.figure(figsize=(8,5))
sns.scatterplot(data=df, x="general_damages", y="total_claim_amount", alpha=0.6)
sns.regplot(data=df, x="general_damages", y="total_claim_amount", scatter=False, color="red")
plt.title("Relationship Between General Damages and Total Claim Amount")
plt.show()


#injury duration days vs claim amounts
plt.figure(figsize=(8,5))
sns.scatterplot(data=df, x="injury_duration_days", y="total_claim_amount", alpha=0.6)
sns.regplot(data=df, x="injury_duration_days", y="total_claim_amount", scatter=False, color="red")
plt.title("Relationship Between Injury Duration and Total Claim Amount")
plt.show()

#Medical Treatment Costs vs Total Claim Amount

plt.figure(figsize=(8,5))
sns.scatterplot(
    data=df,
    x="medical_treatment_costs",
    y="total_claim_amount",
    alpha=0.6
)
sns.regplot(
    data=df,
    x="medical_treatment_costs",
    y="total_claim_amount",
    scatter=False,
    color="red"
)
plt.title("Relationship Between Medical Treatment Costs and Total Claim Amount")
plt.xlabel("Medical Treatment Costs (£)")
plt.ylabel("Total Claim Amount (£)")
plt.show()

#Work Absence Duration Days vs Total Claim Amount
plt.figure(figsize=(8,5))
sns.scatterplot(
    data=df,
    x="work_absence_duration_days",
    y="total_claim_amount",
    alpha=0.6
)
sns.regplot(
    data=df,
    x="work_absence_duration_days",
    y="total_claim_amount",
    scatter=False,
    color="red"
)
plt.title("Relationship Between Work Absence Duration and Total Claim Amount")
plt.xlabel("Work Absence Duration (Days)")
plt.ylabel("Total Claim Amount (£)")
plt.show()

#Our model predictors:
model_features = [
    "general_damages",
    "medical_treatment_costs",
    "work_absence_duration_days",
    "hospital_admission_required",
    "hospital_visit_required",
    "emergency_score"
]

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import pandas as pd

# Choosing predictors (X) and target variable (y)
X = df[model_features]
y = df["total_claim_amount"]

# Split data into training/testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Build and train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Display coefficients
coefficients = pd.DataFrame({
    "Feature": model_features,
    "Coefficient": model.coef_
})

print(coefficients)
print("Intercept:", model.intercept_)
#Should this be visualised?

"""general damages and medical treatment costs are the strongest contributors to claim values.

Hospital-related indicators and emergency services also add substantial amounts to claim estimates.

The negative coefficient for work absence likely reflects overlap with general damages, since general damages already capture much of the injury severity.
"""

#Test the total claim amount estimation on the three provided test samples to evaluate predictive accuracy and refine parameters based on observed outcomes.
task_c_test_data = {
    "client_id": [1.0, 6.0, 8.0],
    "claim_value_category": [1.0, 2.0, 2.0],
    "injury_duration_days": [33.0, 44.0, 42.0],
    "hospital_visit_required": [1.0, 1.0, 1.0],
    "medical_care_sought": [1.0, 1.0, 1.0],
    "hospital_admission_required": [0.0, 0.0, 1.0],
    "currently_unemployed_due_to_injury": [0.0, 1.0, 0.0],
    "work_absence_duration_days": [2.0, 12.0, 0.0],
    "work_absence_required": [0.0, 1.0, 0.0],
    "rehabilitation_recommended": [0.0, 1.0, 1.0],
    "rehabilitation_completed": [0.0, 1.0, 1.0],
    "minor_claimant_at_initial_assessment": [0.0, 0.0, 0.0],
    "defendant_title_code": [0.0, 1.0, 0.0],
    "liability_admission_status": ["A", "A", "A"],
    "liability_type": ["motor", "motor", "motor"],
    "claimant_age_at_incident": [55.0, 31.0, 47.0],
    "liability_denial_reasons": ["", "", ""],
    "claim_rejection_code": ["", "", ""],
    "claims_management_exit_notes": ["", "", ""],
    "claims_resolution_exit_notes": ["", "", ""],
    "claims_resolution_closure_code": ["", "", ""],
    "rental_vehicle_expense": [0.0, 0.0, 0.0],
    "home_care_services_cost": [0.0, 0.0, 0.0],
    "employment_disadvantage_compensation": [0.0, 0.0, 0.0],
    "career_satisfaction_loss_compensation": [0.0, 0.0, 0.0],
    "asset_utility_loss_compensation": [0.0, 0.0, 0.0],
    "medical_treatment_costs": [125.32, 250.73, 500.12],
    "general_damages": [6056.74, 14563.83, 24008.63],
    "insurance_deductible_amount": [50.0, 100.0, 0.0],
    "car_damage_severity": ["none", "minor", "severe"],
    "total_claim_amount": [6232.06, 14914.56, 24508.75],
    "injury_type_classifications": [
        "{'Internal Injury', 'Psychological Issues'}",
        "{'Facial Injury', 'Psychological Issues', 'Soft Tissue Injury'}",
        "{'Head Injury', 'Internal Injury'}"
    ],
    "rehabilitation_program_types": [
        "{'Unknown'}",
        "{'exercises', 'pain relief'}",
        "{'miscellaneous', 'scans and imaging', 'surgery'}"
    ],
    "claimant_current_age_years": [55.0, 31.0, 47.0],
    "medical_attention_delay_days": [0.0, 0.0, 0.0],
    "emergency_services_attended": ["none", "ambulance", "ambulance_and_police"],
}

df_samples_task_c = pd.DataFrame(task_c_test_data)

# Clean + map car damage severity
df_samples_task_c["car_damage_severity"] = (
    df_samples_task_c["car_damage_severity"]
        .astype(str)
        .str.strip()
        .str.lower()
)

car_damage_map = {"none": 0, "minor": 1, "moderate": 2, "severe": 3}
df_samples_task_c["car_damage_score"] = df_samples_task_c["car_damage_severity"].map(car_damage_map)

# Map emergency services to numeric score
emergency_map = {
    "none": 0,
    "police": 1,
    "ambulance": 1,
    "ambulance_and_police": 2
}
df_samples_task_c["emergency_score"] = df_samples_task_c["emergency_services_attended"].map(emergency_map)

#  3. Use the same model features as our your regression

model_features = [
    "general_damages",
    "medical_treatment_costs",
    "work_absence_duration_days",
    "hospital_admission_required",
    "hospital_visit_required",
    "emergency_score"
]

X_samples = df_samples_task_c[model_features]

# 4. Predict claim amounts using the trained model

sample_predictions = model.predict(X_samples)
df_samples_task_c["predicted_claim_amount"] = sample_predictions

#  5. Compare predicted vs actual + error

df_samples_task_c["error"] = df_samples_task_c["predicted_claim_amount"] - df_samples_task_c["total_claim_amount"]

print(df_samples_task_c[[
    "client_id",
    "total_claim_amount",
    "predicted_claim_amount",
    "error"
]])

"""The model produced reasonably accurate predictions for all three test cases, with errors ranging from £128 to £1230. In relative terms, the prediction errors remain low (2–5%), demonstrating strong consistency and good generalisation to unseen data. The model shows a slight tendency to overestimate claim amounts, but overall performs reliably within acceptable tolerance limits for insurance claim estimation."""